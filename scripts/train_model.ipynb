{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula 1: Importações e Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install scipy\n",
    "!pip install scikit-image\n",
    "!pip install scikit-learn\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier # Opcional\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import pickle # Para salvar o scaler e o modelo\n",
    "import os # Para garantir que os caminhos de arquivo funcionem bem\n",
    "from sklearn.tree import export_text # Para exportar regras da árvore de decisão\n",
    "\n",
    "# --- Configurações ---\n",
    "INPUT_FEATURES_CSV = 'dataset_with_features.csv'\n",
    "MODEL_CHOICE = 'logistic' # Escolha: 'logistic', 'svm_linear', 'decision_tree'\n",
    "TEST_SIZE_RATIO = 0.2   # Proporção do dataset para o conjunto de teste (ex: 0.2 para 20%)\n",
    "RANDOM_STATE_SEED = 42  # Para reprodutibilidade\n",
    "\n",
    "# Caminhos para salvar o scaler e o modelo treinado\n",
    "SCALER_FILE_PATH = 'scaler.pkl'\n",
    "MODEL_FILE_PATH = 'trained_model.pkl'\n",
    "MODEL_PARAMS_FILE_PATH = 'model_parameters.txt' # Para salvar pesos e bias em formato de texto\n",
    "# ---------------------\n",
    "\n",
    "print(\"Configurações carregadas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula 2: Função para Salvar Parâmetros do Modelo para C/C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_parameters_for_c(model, scaler, model_type, feature_names_list_param, file_path):\n",
    "    \"\"\"Salva os parâmetros do modelo e do scaler em um arquivo de texto para fácil implementação em C/C++.\"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(f\"// --- Parâmetros do Modelo ({model_type}) e Scaler para Implementação em C/C++ ---\\n\")\n",
    "        f.write(f\"// Gerado em: {pd.Timestamp.now()}\\n\")\n",
    "        \n",
    "        f.write(\"\\n// Parâmetros do StandardScaler (média e escala/desvio_padrão):\\n\")\n",
    "        f.write(\"// Use estes para escalar as features no ESP32 antes da predição\\n\")\n",
    "        f.write(f\"// Número de features que o scaler espera: {len(scaler.mean_)}\\n\")\n",
    "        f.write(\"// Nomes das features (na ordem esperada pelo scaler/modelo):\\n\")\n",
    "        \n",
    "        if feature_names_list_param:\n",
    "            for i, name in enumerate(feature_names_list_param):\n",
    "                f.write(f\"// Feature {i}: {name}\\n\")\n",
    "        else:\n",
    "            f.write(\"// Nomes das features não disponíveis. Ordem é crucial.\\n\")\n",
    "\n",
    "        f.write(\"const float scaler_means[] = {\")\n",
    "        for i, mean_val in enumerate(scaler.mean_):\n",
    "            f.write(f\"{mean_val:.8f}f\")\n",
    "            if i < len(scaler.mean_) - 1:\n",
    "                f.write(\", \")\n",
    "        f.write(\"};\\n\")\n",
    "\n",
    "        f.write(\"const float scaler_scales[] = {\") # scale_ é o desvio padrão para StandardScaler\n",
    "        for i, scale_val in enumerate(scaler.scale_):\n",
    "            f.write(f\"{scale_val:.8f}f\")\n",
    "            if i < len(scaler.scale_) - 1:\n",
    "                f.write(\", \")\n",
    "        f.write(\"};\\n\")\n",
    "\n",
    "        if model_type in ['logistic', 'svm_linear']:\n",
    "            # model.coef_ é geralmente [[w1, w2, ...]] para classificação binária\n",
    "            weights = model.coef_[0]\n",
    "            bias = model.intercept_[0]\n",
    "            f.write(f\"\\n// Parâmetros do Modelo ({model_type}):\\n\")\n",
    "            f.write(\"// y_pred_raw = w[0]*f_scaled[0] + ... + w[n-1]*f_scaled[n-1] + bias\\n\")\n",
    "            if model_type == 'logistic':\n",
    "                 f.write(\"// P(y=1) = 1 / (1 + exp(-y_pred_raw)); Prever 1 se P(y=1) > 0.5\\n\")\n",
    "            else: # svm_linear\n",
    "                 f.write(\"// Prever 1 se y_pred_raw > 0 (ou outro limiar de decisão)\\n\")\n",
    "            \n",
    "            f.write(\"const float model_weights[] = {\")\n",
    "            for i, weight in enumerate(weights):\n",
    "                f.write(f\"{weight:.8f}f\")\n",
    "                if i < len(weights) - 1:\n",
    "                    f.write(\", \")\n",
    "            f.write(\"};\\n\")\n",
    "            f.write(f\"const float model_bias = {bias:.8f}f;\\n\")\n",
    "            \n",
    "            # Imprimir no console do notebook também\n",
    "            print(\"\\n--- Parâmetros do Modelo e Scaler para Implementação em C/C++ ---\")\n",
    "            if feature_names_list_param:\n",
    "                print(f\"Nomes das Features (ordem): {feature_names_list_param}\")\n",
    "            print(f\"Scaler Means: {scaler.mean_}\")\n",
    "            print(f\"Scaler Scales (Std Devs): {scaler.scale_}\")\n",
    "            print(f\"Model Weights: {weights}\")\n",
    "            print(f\"Model Bias: {bias}\")\n",
    "        \n",
    "        elif model_type == 'decision_tree':\n",
    "            f.write(\"\\n// Parâmetros da Árvore de Decisão:\\n\")\n",
    "            f.write(\"// A exportação direta de uma árvore para C requer uma lógica de if/else.\\n\")\n",
    "            f.write(\"// Use sklearn.tree.export_text(model, feature_names=...) para ver as regras.\\n\")\n",
    "            tree_rules = export_text(model, feature_names=feature_names_list_param)\n",
    "            f.write(\"\\n// Regras da Árvore de Decisão (para referência):\\n\")\n",
    "            f.write(tree_rules + \"\\n\")\n",
    "            print(\"\\nRegras da Árvore de Decisão (para referência):\")\n",
    "            print(tree_rules)\n",
    "        \n",
    "        print(f\"\\nParâmetros e/ou regras do modelo salvos em texto em: {file_path}\")\n",
    "\n",
    "print(\"Função save_model_parameters_for_c definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula 3: Carregamento e Pré-processamento dos Dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- Iniciando Treinamento do Modelo ({MODEL_CHOICE}) ---\")\n",
    "\n",
    "# 1. Carregar Dados\n",
    "try:\n",
    "    df_features = pd.read_csv(INPUT_FEATURES_CSV)\n",
    "    print(f\"Dataset de features lido: {INPUT_FEATURES_CSV} ({len(df_features)} janelas, {len(df_features.columns)-1} features + label)\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivo de features não encontrado: {INPUT_FEATURES_CSV}\")\n",
    "    print(\"Certifique-se de que o script 'feature_extractor.py' foi executado com sucesso.\")\n",
    "    # Em um notebook, você pode querer parar aqui ou carregar um df de exemplo\n",
    "    df_features = None \n",
    "except Exception as e:\n",
    "    print(f\"ERRO ao ler {INPUT_FEATURES_CSV}: {e}\")\n",
    "    df_features = None\n",
    "\n",
    "if df_features is not None:\n",
    "    if 'label' not in df_features.columns:\n",
    "        print(f\"ERRO: A coluna 'label' não foi encontrada em {INPUT_FEATURES_CSV}.\")\n",
    "        df_features = None # Impede a execução do resto se o label não existir\n",
    "    \n",
    "    # Tratamento de NaNs\n",
    "    if df_features.isnull().sum().any():\n",
    "        print(\"AVISO: Valores nulos (NaN) encontrados no dataset de features.\")\n",
    "        print(\"Preenchendo NaNs numéricos com a média da coluna...\")\n",
    "        for col in df_features.columns:\n",
    "            if df_features[col].isnull().any() and pd.api.types.is_numeric_dtype(df_features[col]):\n",
    "                if col != 'label': # Não preenche a coluna de label\n",
    "                    df_features[col] = df_features[col].fillna(df_features[col].mean())\n",
    "        \n",
    "        if df_features.isnull().sum().any():\n",
    "            print(\"AVISO: Ainda há NaNs após o preenchimento com média. Removendo linhas com NaNs restantes.\")\n",
    "            df_features.dropna(inplace=True)\n",
    "            print(f\"Novo tamanho do dataset após remoção de NaNs: {len(df_features)}\")\n",
    "            if len(df_features) == 0:\n",
    "                print(\"Dataset vazio após remoção de NaNs. Saindo.\")\n",
    "                df_features = None\n",
    "    \n",
    "    if df_features is not None:\n",
    "        X = df_features.drop('label', axis=1)\n",
    "        y = df_features['label']\n",
    "        feature_names = list(X.columns) # Salva os nomes das features\n",
    "\n",
    "        print(f\"\\nNúmero de amostras: {len(X)}\")\n",
    "        print(f\"Número de features: {len(feature_names)}\")\n",
    "        print(f\"Nomes das Features: {feature_names}\")\n",
    "        print(f\"Distribuição das classes:\\n{y.value_counts(normalize=True)}\")\n",
    "        \n",
    "        # Visualizar as primeiras linhas de X e y\n",
    "        print(\"\\nPrimeiras 5 linhas das Features (X):\")\n",
    "        print(X.head())\n",
    "        print(\"\\nPrimeiras 5 linhas dos Rótulos (y):\")\n",
    "        print(y.head())\n",
    "else:\n",
    "    print(\"Não foi possível carregar ou processar os dados. Verifique as mensagens de erro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula 4: Divisão Treino/Teste e Escalonamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X' in locals() and 'y' in locals(): # Verifica se X e y foram definidos na célula anterior\n",
    "    # 2. Dividir em Treino e Teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=TEST_SIZE_RATIO, \n",
    "        random_state=RANDOM_STATE_SEED, \n",
    "        stratify=y # Importante para manter a proporção das classes em treino e teste\n",
    "    )\n",
    "    print(f\"\\nDataset dividido em {len(X_train)} amostras de treino e {len(X_test)} de teste.\")\n",
    "\n",
    "    # 3. Escalonamento de Features\n",
    "    scaler = StandardScaler()\n",
    "    # Ajusta o scaler APENAS nos dados de treino\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    # Aplica a mesma transformação aos dados de teste\n",
    "    X_test_scaled = scaler.transform(X_test) \n",
    "    \n",
    "    # Converte de volta para DataFrames para manter nomes de colunas (opcional, mas bom para inspeção)\n",
    "    X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_names)\n",
    "    X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=feature_names)\n",
    "    \n",
    "    print(\"Features escalonadas usando StandardScaler.\")\n",
    "    print(\"\\nPrimeiras 5 linhas das Features de Treino Escalonadas:\")\n",
    "    print(X_train_scaled_df.head())\n",
    "\n",
    "    # Salva o scaler treinado\n",
    "    with open(SCALER_FILE_PATH, 'wb') as f_scaler:\n",
    "        pickle.dump(scaler, f_scaler)\n",
    "    print(f\"\\nScaler treinado salvo em: {SCALER_FILE_PATH}\")\n",
    "else:\n",
    "    print(\"X e/ou y não foram definidos. Execute a célula de carregamento de dados primeiro.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula 5: Escolha, Treinamento e Salvamento do Modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'X_train_scaled' in locals() and 'y_train' in locals(): # Verifica se os dados de treino existem\n",
    "    # 4. Escolher e Treinar o Modelo\n",
    "    print(f\"\\nTreinando modelo: {MODEL_CHOICE}...\")\n",
    "    if MODEL_CHOICE == 'logistic':\n",
    "        model = LogisticRegression(solver='liblinear', random_state=RANDOM_STATE_SEED, class_weight='balanced')\n",
    "    elif MODEL_CHOICE == 'svm_linear':\n",
    "        model = SVC(kernel='linear', probability=True, random_state=RANDOM_STATE_SEED, class_weight='balanced')\n",
    "    elif MODEL_CHOICE == 'decision_tree':\n",
    "        model = DecisionTreeClassifier(random_state=RANDOM_STATE_SEED, max_depth=5, class_weight='balanced') \n",
    "    else:\n",
    "        print(f\"ERRO: Escolha de modelo inválida: {MODEL_CHOICE}.\")\n",
    "        model = None # Impede a execução do resto se o modelo for inválido\n",
    "\n",
    "    if model is not None:\n",
    "        model.fit(X_train_scaled, y_train) # Usa X_train_scaled (numpy array)\n",
    "        print(\"Modelo treinado.\")\n",
    "\n",
    "        # Salva o modelo treinado\n",
    "        with open(MODEL_FILE_PATH, 'wb') as f_model:\n",
    "            pickle.dump(model, f_model)\n",
    "        print(f\"Modelo treinado salvo em: {MODEL_FILE_PATH}\")\n",
    "else:\n",
    "    print(\"Dados de treino (X_train_scaled, y_train) não encontrados. Execute as células anteriores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula 6: Avaliação do Modelo no Conjunto de Teste\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals() and 'X_test_scaled' in locals() and 'y_test' in locals(): # Verifica se tudo necessário existe\n",
    "    # 5. Avaliação no Conjunto de Teste\n",
    "    print(\"\\n--- Avaliação no Conjunto de Teste ---\")\n",
    "    y_pred_test = model.predict(X_test_scaled) # Usa X_test_scaled (numpy array)\n",
    "    \n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    print(f\"Acurácia no Teste: {accuracy_test:.4f}\")\n",
    "    \n",
    "    print(\"\\nMatriz de Confusão (Teste):\")\n",
    "    cm = confusion_matrix(y_test, y_pred_test)\n",
    "    print(cm)\n",
    "    # Para visualização mais clara da matriz de confusão:\n",
    "    # import seaborn as sns\n",
    "    # import matplotlib.pyplot as plt\n",
    "    # sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "    # plt.xlabel(\"Previsto\")\n",
    "    # plt.ylabel(\"Real\")\n",
    "    # plt.title(\"Matriz de Confusão - Teste\")\n",
    "    # plt.show()\n",
    "\n",
    "    print(\"\\nRelatório de Classificação (Teste):\")\n",
    "    # Certifique-se de que target_names corresponda às suas classes e à ordem em model.classes_\n",
    "    # Se y é 0 e 1, e model.classes_ é [0, 1], então os nomes são para 0 e depois para 1.\n",
    "    class_names = [f'NaoTremor ({model.classes_[0]})', f'Tremor ({model.classes_[1]})'] if len(model.classes_)==2 else None\n",
    "    print(classification_report(y_test, y_pred_test, target_names=class_names))\n",
    "else:\n",
    "    print(\"Modelo ou dados de teste não encontrados. Execute as células anteriores.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula 7: Validação Cruzada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals() and 'X_train_scaled' in locals() and 'y_train' in locals():\n",
    "    # 6. Validação Cruzada (no conjunto de treino)\n",
    "    print(\"\\n--- Validação Cruzada (no conjunto de treino escalonado) ---\")\n",
    "    # Usa X_train_scaled e y_train\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy') # 5 folds\n",
    "    print(f\"Acurácias da Validação Cruzada (5-fold): {cv_scores}\")\n",
    "    print(f\"Acurácia Média da Validação Cruzada: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")\n",
    "else:\n",
    "    print(\"Modelo ou dados de treino não encontrados para validação cruzada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Célula 8: Salvar Parâmetros do Modelo e Scaler para C/C++\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'model' in locals() and 'scaler' in locals() and 'feature_names' in locals():\n",
    "    # 7. Salvar Parâmetros do Modelo para C/C++\n",
    "    # Passar 'feature_names' que guardamos de X antes de escalar.\n",
    "    # A função 'save_model_parameters_for_c' foi definida na Célula 2.\n",
    "    save_model_parameters_for_c(model, scaler, MODEL_CHOICE, feature_names, MODEL_PARAMS_FILE_PATH)\n",
    "    print(\"\\nScript de treinamento de modelo (execução no notebook) concluído.\")\n",
    "else:\n",
    "    print(\"Modelo, scaler, ou feature_names não definidos. Não foi possível salvar os parâmetros para C.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
